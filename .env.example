# Inference Service Configuration
INFERENCE_PORT=8888
# Path to the model directory (mounted to /app/models) or HuggingFace ID
# If you wish to use the original bots, you have to pass safetensors as false and load "hakurei/lotus-12B"
INFERENCE_MODEL="Ryex/lotus-fixed"

# Quantization Level: 4bit, 8bit, 16bit, none
QUANTIZATION=4bit

# Use SafeTensors: TRUE, FALSE
USE_SAFETENSORS=TRUE

# Device Map: auto, cuda:0, etc.
DEVICE_MAP=auto

# Gateway Service Configuration
GATEWAY_PORT=9009
INFERENCE_MODEL_NAME="Ryex/lotus-fixed"
INFERENCE_AUTHOR="Harubaru with edits by Ryex"
INFERENCE_DESCRIPTION=lotus-12b
